{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3919e547",
   "metadata": {},
   "source": [
    "# Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cf6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vangelis/PycharmProjects/veritas/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import AutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "import preprocessor as p\n",
    "from geopy.geocoders import Nominatim\n",
    "from os import listdir\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7240f5a",
   "metadata": {},
   "source": [
    "# Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfbbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_KEY = \"xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "APP_SECRET = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "SAMPLES_DIR = \"./data\"\n",
    "MAX_SAMPLES = 2 # Limit of the top n lines to read in each file sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0f7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_website = pd.read_csv(\"websites.csv\")\n",
    "trust_websites_map: map = {}\n",
    "sites = list(trust_website[\"site\"])\n",
    "site_scores = list(trust_website[\"trust\"])\n",
    "for i in range(0, len(sites)):\n",
    "    trust_websites_map.setdefault(sites[i], site_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e3a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_trust_score(external_url: str):\n",
    "    if external_url:\n",
    "        return trust_websites_map.get(external_url, 0)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310c9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bearer_token():\n",
    "    url = 'https://api.twitter.com/oauth2/token'\n",
    "    auth = (APP_KEY, APP_SECRET)\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "\n",
    "    response = requests.post(url, auth=auth, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a91e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_url_from_tweet(tweet)->set:\n",
    "    external_urls_objects = tweet['entities'].get(\"urls\", None)\n",
    "    if external_urls_objects:\n",
    "        for url_object in external_urls_objects:\n",
    "            try:\n",
    "                url = url_object['display_url'].split('/', 1)[0]\n",
    "                if \"twitter.com\" not in url:\n",
    "                    return url\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "        return None;\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d39ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_from_user(user):\n",
    "    followers_count = user[\"public_metrics\"].get(\"followers_count\", None)\n",
    "    tweet_count = user[\"public_metrics\"].get(\"tweet_count\", None)\n",
    "    \n",
    "    return (followers_count, tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a4758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags_texts(hashtags: list):\n",
    "    hashtags_list = []\n",
    "    for hashtag in hashtags:\n",
    "        hashtags_list.append(hashtag.get(\"tag\", None))\n",
    "        \n",
    "    return hashtags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1b96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_from_user(user):\n",
    "    \n",
    "    location = user.get(\"location\", None)\n",
    "    \n",
    "    if location:\n",
    "        geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "        parsed_location = geolocator.geocode(location, addressdetails=True)\n",
    "        if parsed_location:\n",
    "            address = parsed_location.raw[\"address\"]\n",
    "            country = address.get(\"country\", None)\n",
    "            state = address.get(\"state\", None)  \n",
    "            \n",
    "            return (location, country, state)\n",
    "    else:\n",
    "        return (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c000a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(user_id: str):\n",
    "    url = 'https://api.twitter.com/2/users'\n",
    "    params = {\n",
    "        'ids': user_id,\n",
    "        'user.fields': 'location,public_metrics'\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {get_bearer_token()}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)  \n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200 and \"errors\" not in response.json():\n",
    "        data = response.json()[\"data\"][0]\n",
    "        return data\n",
    "    elif response.status_code == 429:\n",
    "        print(\"Falling asleep for 15 minutes...\")\n",
    "        time.sleep(960)\n",
    "        return get_user(user_id)\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec98911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(tweet_id: str):\n",
    "    url = 'https://api.twitter.com/2/tweets'\n",
    "    params = {\n",
    "        'ids': tweet_id,\n",
    "        'tweet.fields': 'referenced_tweets,author_id,created_at,public_metrics,entities'\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {get_bearer_token()}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200 and \"errors\" not in response.json():\n",
    "        data = response.json()[\"data\"][0]\n",
    "        if \"referenced_tweets\" in data:\n",
    "            return get_tweet(data[\"referenced_tweets\"][0][\"id\"])\n",
    "        else:\n",
    "            return data\n",
    "    elif response.status_code == 429:\n",
    "        print(\"Falling asleep for 15 minutes...\")\n",
    "        time.sleep(960)\n",
    "        return get_tweet(tweet_id)\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dac5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_row(data: map):\n",
    "    try:\n",
    "        created_at = data[\"created_at\"]\n",
    "        tweet_id = data[\"id\"]\n",
    "        user_id =data[\"author_id\"]\n",
    "        text = data[\"text\"]\n",
    "        retweets_count = data[\"public_metrics\"][\"retweet_count\"]\n",
    "        likes_count = data[\"public_metrics\"][\"like_count\"]\n",
    "        replies_count = data[\"public_metrics\"][\"reply_count\"]\n",
    "        hashtags = data[\"entities\"].get(\"hashtags\", None)\n",
    "        hashtags_text = None\n",
    "        if hashtags:\n",
    "            hashtags_text = get_hashtags_texts(hashtags)\n",
    "        url = get_external_url_from_tweet(data)\n",
    "        tweet_trust_score = get_tweet_trust_score(url)\n",
    "        user = get_user(user_id)\n",
    "        location, country, state = get_location_from_user(user)\n",
    "        followers_count, tweet_count = get_metrics_from_user(user)\n",
    "\n",
    "        row = {\n",
    "            \"createdAt\": [created_at],\n",
    "            \"tweetId\": [tweet_id],\n",
    "            \"userId\": user_id,\n",
    "            \"user_followers_count\": [followers_count],\n",
    "            \"user_tweet_count\": [tweet_count],\n",
    "            \"location\": [location],\n",
    "            \"country\": [country],\n",
    "            \"state\": [state],\n",
    "            \"text\": [text],\n",
    "            \"retweetsCount\": [retweets_count],\n",
    "            \"likesCount\": [likes_count],\n",
    "            \"repliesCount\": [replies_count],\n",
    "            \"hashtags\": [hashtags_text],\n",
    "            \"url\": [url],\n",
    "            \"tweetTrustScore\": [tweet_trust_score]\n",
    "        }\n",
    "        \n",
    "        return row\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e4e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_files():\n",
    "    return listdir(SAMPLES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a15e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rows_from_tweetIds(df, tweetIds: list):\n",
    "    for i, tweet_id in enumerate(lines):\n",
    "        tweet_id = tweet_id.strip()\n",
    "        data = get_tweet(tweet_id)\n",
    "        if data:\n",
    "            row = get_sample_row(data)\n",
    "            if row:\n",
    "                new_df = pd.DataFrame(row)\n",
    "                df = pd.concat([df, new_df], ignore_index=True)\n",
    "        if i == MAX_SAMPLES: break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ff845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2023-02_tweet_ids.txt is being processed...\n",
      "'entities'\n",
      "File 2023-01_tweet_ids.txt is being processed...\n"
     ]
    }
   ],
   "source": [
    "samples_files = get_samples_files()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in samples_files:\n",
    "    sample_file_path = os.path.join(SAMPLES_DIR, file_name)\n",
    "    print(\"File \"+file_name+\" is being processed...\")\n",
    "    with open(sample_file_path) as sample_file:\n",
    "        lines = sample_file.readlines()\n",
    "        df = collect_rows_from_tweetIds(df, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68923edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"collected_samples.csv\", quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287c8be",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet: str):\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = tweet.replace('\\d+', '')\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71759208",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "texts = list(df[\"text\"])\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/media/vangelis/vag/sentiment_amalysis_final\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "    text = preprocess_tweet(text)\n",
    "    label = 1 if classifier(text)=='LABEL_1' else 0\n",
    "    labels.append()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
